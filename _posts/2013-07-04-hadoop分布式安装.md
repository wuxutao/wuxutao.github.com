---
layout: post
category : 数据挖掘
tags : [hadoop, 大数据, 数据挖掘, 数据分析]
---

> 平和而执着， 谦虚而无畏

为公司开发推荐系统，改系统共分为以下几层：最底层openstack作为私有云平台，上层是hadoop的数据挖掘、分析平台，然后是分布式日志收集系统及爬虫数据，最后是推进引擎。

言归正传，今天做的是搭建hadoop分布式集群，用的是4台基于opensatck的云机；本来是想用puppet来搭建的，后来因为任务紧，而puppet掌握不熟练，所以先普通搭建，步骤如下，已作备忘：

1. datanaode和jobtracker放在一台机器上，修改该机器hostname未h-master
    sudo hostname h-master
2. 修改/etc/hosts 和 /etc/hostname 主机名称
3. 按照步骤1和2修改其他三台主机名称分别未h-slave-1,h-slave-2,h-slave-3
4. 在每台主机/etc/hosts下添加如下数据：

        10.0.0.4 h-master
        10.0.0.6 h-slave-1
        10.0.0.8 h-slave-2
        10.0.0.9 h-slave-3
5. 在每台机器创建hadoop组及hadoop用户：
        
        sudo addgroup hadoop
        sudo adduser -ingroup hadoop hadoop
6. 修改每台机器的/etc/sudoers,赋予hadoop超级用户权限:
    
        hadoop  ALL=(ALL:ALL) ALL
7. 每台机器安装java环境，装在/opt/java下
8. 每台机器修改/etc/profile,增加java环境变量：
    
        export JAVA_HOME=/opt/java
        export PATH=$JAVA_HOME/bin:$PATH
        export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
9. 每台机器安装ssh及rsync:
    
        sudo apt-get install ssh
        sudo apt-get install rsync
10. 创建无密码登录环境： 
        
        * 在h-master上运行
    
                ssh-keygen -t rsa -P ""
        * 生成密钥，位置：~/.ssh/id_rsa.pub
        * 分别运行:
                
                ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@10.0.0.4
                ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@10.0.0.6
                ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@10.0.0.8
                ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@10.0.0.9
        * 如果ssh端口非22，命令改为
                ssh-copy-id -i ~/.ssh/id_rsa.pub "-p 10022 hadoop@10.0.0.4"
        * 然后运行
                ssh h-master
                ssh h-slave-1
                ssh h-slave-2
                ssh h-slave-3
        * 运行一次是因为第一次登录需要选择yes，否则启动start-all.sh时会失败
11. h-master安装hadoop，下载hadoop-1.2.0.tar.gz
12. 解压hadoop-1.2.0.tar.gz到/opt/hadoop,修改hadoop用户组
    
        sudo tar zxvf hadoop-1.2.0.tar.gz -C /opt
        sudo mv hadoop-1.2.0 hadoop
        sudo chown -R hadoop:hadoop hadoop-1.2.0
13. 修改/opt/hadoop/conf/hadoop-env.sh,打开JAVA_HOME注释，修改如下：
    
        export JAVA_HOME=/opt/java
14. 修改/opt/conf/core-site.xml,内容如下：
    
        <?xml version="1.0"?>
        <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

        <!-- Put site-specific property overrides in this file. -->

        <configuration>
            <property>
                <name>fs.default.name</name>
                <value>hdfs://h-master:9000</value>
            </property>
        </configuration>

15. 修改/opt/conf/mapred-site.xml,修改内容如下：
        
        <?xml version="1.0"?>
        <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

        <!-- Put site-specific property overrides in this file. -->

            <configuration>
                <property>
                    <name>mapred.job.tracker</name>
                    <value>h-master:9001</value>
                </property>
            </configuration>
16. 修改/opt/hadoop/hdfs-site.xml,修改内容如下：
    
        <?xml version="1.0"?>
        <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

        <!-- Put site-specific property overrides in this file. -->

            <configuration>
                <property>
                    <name>dfs.replication</name>
                    <value>2</value>
                </property>
            </configuration>
17. 修改/opt/hadoop/conf/masters,修改如下：
    
        h-master
18. 修改/opt/hadoop/conf/slaves,修改如下：
    
        h-slave-1
        h-slave-2
        h-slave-3
19. 把h-master上的/opt/hadoop复制到每个salve机器的/opt/hadoop目录；并把改目录权限设置为hadoop:hadoop
20. 安装完毕，格式化hdfs；在h-master机器上，进入到/opt/hadoop目录，
    
        bin/hadoop namenode -format
21. 启动，h-master机器，/opt/hadoop目录：
        
        bin/start-all.sh
22. master运行jps:
    
        15355 NameNode
        15763 SecondaryNameNode
        20086 Jps
        15852 JobTracker
23. slave运行jps:
    
        15504 Jps
        14444 DataNode
        14716 TaskTracker

成功！！！

####后续发现问题修改
#####HDFS空间为0
1. 经检查为core-site.html的hdfs:h-master:9000绑定的端口是127.0.1.1,解决方法未去掉/etc/hosts中的
        
        127.0.1.1   h-master

#####修改hdfs所在的磁盘
1. 因为我的是云机，/只有10G，而/opt为300G，所以需要把hdfs限定在/opt下，只需修改hdfs-site.xml,指定dfs.data.dir即可
